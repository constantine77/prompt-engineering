{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50cb01bd",
   "metadata": {},
   "source": [
    "# Create AI application in minutes with OpenAI API\n",
    "\n",
    "### Introduction\n",
    "\n",
    "OpenAI released of ChatGPT’s API, allowing developers easy access to building applications with the model.\n",
    "This demo will discuss important concepts on using the new ChatGPT API to build applications and how you can quickly get started.\n",
    "\n",
    "### How ChatGPT Works:\n",
    "\n",
    "The Models that power ChatGPT focus on the following ares:\n",
    "* Large Language Models (LLM)\n",
    "* Self-Attention Mechanism\n",
    "* Reinforcement Learning from Human Feedback (RLHF).\n",
    "\n",
    "### GPT - Generative Pre-trained Transformer\n",
    "\n",
    "A transformer is a deep learning model that adopts the mechanism of slef-attention, to differentiate the significance of each part of the input data using weigths.\n",
    "\n",
    "### GPT - 3 family of models are generative models\n",
    "\n",
    "Core techniques:\n",
    "-Next-toekn Prediction\n",
    "-Masked-language modeling\n",
    "\n",
    "### Reinforcement learning from human feedback \n",
    "is a type of machine learning where an agent learns to perform a task by receiving feedback from a human. In this approach, the human provides feedback to the agent in the form of rewards or punishments, depending on the agent's actions. The agent's objective is to maximize the total reward it receives over time.\n",
    "\n",
    "The process typically involves the following steps:\n",
    "\n",
    "The agent performs an action in the environment.\n",
    "The human provides feedback to the agent based on the outcome of the action.\n",
    "The agent updates its policy or strategy based on the feedback.\n",
    "The agent repeats this process over multiple iterations until it learns an optimal policy.\n",
    "This approach is particularly useful in scenarios where it is difficult or impossible to define a reward function mathematically. For example, in some complex tasks such as image captioning or natural language generation, it can be challenging to come up with a reward function that captures all the nuances of the task. In such cases, feedback from a human can provide a more intuitive and nuanced signal for the agent to learn from.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f94033a",
   "metadata": {},
   "source": [
    "### GPT-4 is a large multimodal model that accepts as input, both text and  images and generates text as output.\n",
    "\n",
    "It can work on documents with text and photos, diagrams, or screenshots\n",
    "\n",
    "Some potential limitations of GPT-4 could include:\n",
    "\n",
    "Data Bias: Like any machine learning model, GPT-4 could be susceptible to bias in the data it is trained on. This could result in the model producing biased or unfair outputs.\n",
    "\n",
    "Computational Requirements: The computational requirements for training GPT models increase with the size of the model, which could make it difficult or expensive for some organizations to train or utilize.\n",
    "\n",
    "Ethical Concerns: As GPT models become more advanced and capable of generating realistic human-like language, there is a potential for misuse, such as the generation of fake news or propaganda.\n",
    "\n",
    "Lack of Contextual Understanding: While GPT models have demonstrated impressive language generation capabilities, they still lack a deeper understanding of the context and meaning of the language they generate. This can sometimes result in outputs that are nonsensical or inappropriate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e224b36",
   "metadata": {},
   "source": [
    "### OpenAI API costs:\n",
    "\n",
    "ChatGPT\n",
    "https://openai.com/pricing#language-models\n",
    "\n",
    "Model\tUsage\n",
    "gpt-3.5-turbo\t$0.002 / 1K tokens\n",
    "\n",
    "GPT-4:\n",
    "Model\tPrompt\tCompletion\n",
    "8K context\t$0.03 / 1K tokens\t$0.06 / 1K tokens\n",
    "32K context\t$0.06 / 1K tokens\t$0.12 / 1K tokens\n",
    "\n",
    "1K Tokens = 750 words\n",
    "\n",
    "DALL·E \n",
    "Resolution\tPrice\n",
    "1024×1024\t$0.020 / image\n",
    "512×512\t$0.018 / image\n",
    "256×256\t$0.016 / image\n",
    "\n",
    "Audio models\n",
    "Model\tUsage\n",
    "Whisper\t$0.006 / minute (rounded to the nearest second)\n",
    "\n",
    "### Tokens:\n",
    "https://platform.openai.com/tokenizer\n",
    "\n",
    "In ChatGPT and other language models, a token refers to a unit of text that the model uses to generate language output. Specifically, a token is a sequence of characters or subwords that the model recognizes as a single unit for processing.\n",
    "\n",
    "For example, the word \"chatbot\" may be broken down into several tokens, such as \"chat\" and \"bot\". The model processes each token individually and uses them to generate the final output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b233e73f",
   "metadata": {},
   "source": [
    "### Q/A\n",
    "\n",
    "1. What is ChatGPT plugins that helps access up-to-date information run computations, or use third-party services - how to join plugins waitlist?\n",
    "\n",
    "https://openai.com/blog/chatgpt-plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e28a9b2",
   "metadata": {},
   "source": [
    "### Making ChatGPT requests Using the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1194aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/veles/Applications/dev/myenv/lib/python3.11/site-packages (23.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "# installing the Python OpenAI API\n",
    "!pip install -q openai\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca29b7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/veles/Applications/dev/myenv/bin/python3.11\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b9d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required modules\n",
    "import openai\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e019283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create environment variable\n",
    "os.environ['OPENAI_API_KEY'] = 'XYZ'\n",
    "os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861bea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"sk-XYZ\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e151fe1",
   "metadata": {},
   "source": [
    "### Simple Promt examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acc3c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_role_content = '''You reply as concisely as possible.\n",
    "If you are not sure about an answer, you will respond with \"I don't know\".'''\n",
    "\n",
    "user_role_content = 'Tell me the name of the largest city in the world'\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': system_role_content},\n",
    "    {'role': 'user', 'content': user_role_content}\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages= messages,\n",
    "    temperature=0.5,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "398ff7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Tokyo.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1687217302,\n",
      "  \"id\": \"chatcmpl-7TIaEI5jGwV6tAVsTaCjOtMa3Vf3l\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 3,\n",
      "    \"prompt_tokens\": 52,\n",
      "    \"total_tokens\": 55\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)  # json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa67d234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo.\n"
     ]
    }
   ],
   "source": [
    "r = response['choices'][0]['message']['content']\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d234623",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_role_content = '''You reply as detailed as possible.\n",
    "If you are not sure about an answer, you will respond with \"I don't know\".'''\n",
    "\n",
    "user_role_content = 'Tell me the name of the largest city in the world'\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': system_role_content},\n",
    "    {'role': 'user', 'content': user_role_content}\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages= messages,\n",
    "    temperature=0.5,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a61ff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest city in the world by population is Tokyo, Japan with an estimated population of over 37 million people in the metropolitan area.\n"
     ]
    }
   ],
   "source": [
    "r = response['choices'][0]['message']['content']\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "147d5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_role_content = '''Answer as Luke Skywalker from the Star Wars'''\n",
    "\n",
    "user_role_content = 'Tell me the name of the largest city in the world'\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': system_role_content},\n",
    "    {'role': 'user', 'content': user_role_content}\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages= messages,\n",
    "    temperature=0.5,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18aa010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I cannot provide an accurate answer to that question as the concept of \"world\" and \"city\" may differ in the Star Wars universe. However, in the galaxy far, far away, there are many planets with vast cities, such as Coruscant, which is known for its towering skyscrapers and bustling population.\n"
     ]
    }
   ],
   "source": [
    "r = response['choices'][0]['message']['content']\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12d416ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_role_content = '''You reply as concisely as possible.\n",
    "If you are not sure about an answer, you will respond with \"I don't know\".'''\n",
    "\n",
    "user_role_content = 'How many crewed missions have landed on Mars?'\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': system_role_content},\n",
    "    {'role': 'user', 'content': user_role_content}\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\", #model name\n",
    "    messages= messages,\n",
    "    temperature=0.5,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "820abbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"There have been no crewed missions that have landed on Mars yet.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1687217345,\n",
      "  \"id\": \"chatcmpl-7TIavCA56am7OK51tMrh8pMjYtInT\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 14,\n",
      "    \"prompt_tokens\": 51,\n",
      "    \"total_tokens\": 65\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)  # json "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cd308e",
   "metadata": {},
   "source": [
    "### Promt and API completion parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e410350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interstellar est un film de science-fiction réalisé par Christopher Nolan. Dans ce film, une équipe de scientifiques et d'astronautes est envoyée dans l'espace pour trouver une nouvelle planète habitable pour l'humanité, car la Terre est en danger. Le vaisseau spatial envoie un petit groupe dans un trou de ver pour atteindre une nouvelle galaxie, mais les dangers et les défis ne manquent pas. Le film aborde des thèmes tels que l'amour, la famille, le sacrifice et la survie de l'espèce humaine face à l'adversité. La performance de Matthew McConaughey dans le rôle principal a été saluée par la critique.\n"
     ]
    }
   ],
   "source": [
    "system_role_content = \"You are a good and smart assistant.\"\n",
    "\n",
    "user_role_content = 'Write a short summary in French of the movie \"Interstellar\" by Christopher Nolan'\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': system_role_content},\n",
    "    {'role': 'user', 'content': user_role_content}\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\", #model name\n",
    "    messages= messages,\n",
    "    temperature=1, # between 0 and 2, default 1, higher value provide more creative/diverse results\n",
    "    top_p=1, # nucleus sampling - 1.0 means \"use all tokens in the vocabulary, 0.2 use only 20% more common tokens\"\n",
    "    max_tokens=1000, # maximum number of tokens allowed for the generated answer. \n",
    "    n=1, #How many completions to generate for each prompt.\n",
    "    frequency_penalty=0, #Number between -2.0 and 2.0 (default 0). Higher the value - less chance of probability for repetitive words\n",
    "    presence_penalty=0 #Number between -2.0 and 2.0 (default 0). with higher values encouraging the model to use a greater variety of words.\n",
    "#     stop=[';', '*'] # we can use up to 4 stop sequences\n",
    ")\n",
    "r = response['choices'][0]['message']['content']\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c276547",
   "metadata": {},
   "source": [
    "## Chat Completion Parameters\n",
    "\n",
    "### 1. temperature ###\n",
    "\n",
    "The temperature (between 0 and 2, default 1) is a parameter that controls how much randomness is in the output.\n",
    "\n",
    "The higher the temperature, the more random and creative the answer will be.\n",
    "A higher value too high will make the answer more creative, it will vary with each call, but the model can also hallucinate.\n",
    "\n",
    "\n",
    "### 2. top_p ###\n",
    "**top_p_** aka **nucleus sampling** is an alternative to temperature.\n",
    "\n",
    "The model considers the results of the tokens with _top_p_ probability mass. So 1.0 means \"use all tokens in the vocabulary\" and 0.1 means only the tokens comprising the top 10% probability mass are considered.\n",
    "\n",
    "It's generally recommended to alter either top_p or temperature but not both.\n",
    "\n",
    "\n",
    "### 3. max_tokens ###\n",
    "The completion tokens from the response object or the maximum number of tokens allowed for the generated answer. \n",
    "\n",
    "\n",
    "### 4. n ###\n",
    "How many completions to generate for each prompt.\n",
    "\n",
    "\n",
    "### 5. frequency_penalty ###\n",
    "Number between -2.0 and 2.0 (default 0).\n",
    "\n",
    "Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n",
    "\n",
    "\n",
    "### 6. presence_penalty ###\n",
    "Number between -2.0 and 2.0 (default 0).\n",
    "\n",
    "Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890c7358",
   "metadata": {},
   "source": [
    "### Using DALL-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d6cd523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-GuCouZdJjymi2GPw3lxi9MXo/user-YBK3SmOAZhMMCn4VCmIWQbjE/img-KTONtXhZiuPAI9QoO6iciNn4.png?st=2023-06-19T23%3A16%3A02Z&se=2023-06-20T01%3A16%3A02Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-06-19T18%3A01%3A16Z&ske=2023-06-20T18%3A01%3A16Z&sks=b&skv=2021-08-06&sig=8MAHgdCID3VA8E2pmafTC6/zzw93RQC/bT9B/rkFzbg%3D\n"
     ]
    }
   ],
   "source": [
    "image_prompt = 'An oil painting of a Luke SkyWalker in futuristic word like Interstellar movie'\n",
    "\n",
    "response = openai.Image.create(\n",
    "    prompt=image_prompt,\n",
    "    n=1,\n",
    "    size='1024x1024'\n",
    ")\n",
    "image_url = response['data'][0]['url']\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca1b66b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-GuCouZdJjymi2GPw3lxi9MXo/user-YBK3SmOAZhMMCn4VCmIWQbjE/img-KTONtXhZiuPAI9QoO6iciNn4.png?st=2023-06-19T23%3A16%3A02Z&se=2023-06-20T01%3A16%3A02Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-06-19T18%3A01%3A16Z&ske=2023-06-20T18%3A01%3A16Z&sks=b&skv=2021-08-06&sig=8MAHgdCID3VA8E2pmafTC6/zzw93RQC/bT9B/rkFzbg%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# assume image_url contains the URL of the image\n",
    "image_url = response['data'][0]['url']\n",
    "\n",
    "# display the image\n",
    "display(Image(url=image_url))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3661e93",
   "metadata": {},
   "source": [
    "### Project: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c9e6e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_classify_sentiment(prompt, emotions):\n",
    "    system_prompt = f'''You are an emotionally intelligent assistant.\n",
    "    Classify the sentiment of the user's text with ONLY ONE OF THE FOLLOWING EMOTIONS: {emotions}.\n",
    "    After classifying the text, respond with the emotion ONLY.'''\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ],\n",
    "        max_tokens=20,\n",
    "        temperature=0\n",
    "    )\n",
    "    r = response['choices'][0].message.content\n",
    "    if r == '':\n",
    "        r = 'N/A'\n",
    "        \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "194d28e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "emotions = 'positive, negative'\n",
    "prompt = 'AI will take over the world.'\n",
    "print(gpt_classify_sentiment(prompt, emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b74c4",
   "metadata": {},
   "source": [
    "### Speech Recognition with Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e9c7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"The Lowdown, audio downloads for people who are long on ambition but short on time. The Lowdown, improve your speech, American English, useful tips to help achieve a more professional level of speech. Written and presented by Mark Cavan. Part 1, The Importance of Speech. Hello there. Thank you for choosing The Lowdown. Today I'm going to talk you through a few quick changes that you can make to help improve your quality of speech. A few quick tips that with practice will help keep you ahead of the game. Now before we get to the practical stuff, I'd like to take a moment to talk about the importance of speech as it relates to our professional lives and what our ability to communicate says about us. At the risk of preaching to the converted, it's worth pointing out that the way we speak can say as much about us as the clothes we wear, the cars we drive, or even the newspapers and the magazines we read. Have you ever stood in line at a supermarket and spied the contents of the card in front of you? As the items pile up, many of us can't help making little judgments about the purchaser purely on the basis of the food they're buying. They must have kids with their eating that cereal. Nothing but salad, health freaks. Man, she's not going to lose any weight buying all that junk. Well, so it is with speech. Our pronunciation and the vocabulary we use can often indicate to others our background, our level of education, and our comprehension of events. This is not to say that someone who speaks well is necessarily smart and someone who doesn't speak well is less smart, but people will make assumptions and not always in our favor. Speech sends out signals, gives off clues, and used wisely can be a useful tool to assist you in achieving a greater level of success. You've heard the expression dress for success? Well, think of it as speaking for success. We live and work in a global market. Our expertise is farmed out around the planet. Our clients, colleagues, and customers are international. Phone your insurance company, your bank, and find yourself talking to someone on the other side of the world. We encourage multiculturalism. Keep adding to the melting pot. But rightly or wrongly, English is still regarded as the international language of business. This is not about individual accents so much as clarity in our communication skills. Clear speech sends out the message, I am in control. I can take charge, gaining confidence from those around you. Clear speech will maximize your potential, making you a greater asset to your company and your profession as we work towards a common ground where we can all be understood.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "with open('rr.mp3', 'rb') as audio_file:\n",
    "    transcript = openai.Audio.transcribe('whisper-1', audio_file)\n",
    "    print(transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d2d591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
